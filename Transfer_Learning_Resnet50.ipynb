{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matanlakker/BINA/blob/main/Transfer_Learning_Resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YGU7sq1g4Gr",
        "outputId": "d9b7e37a-3f9c-47c6-a76a-1462325e090d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "id": "blf41uNFg8gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f526593-1ce3-49d4-e8c3-baafa2f8df7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ana film (1).mp4'\t      'Hoveret (1).gdoc'\n",
            "'ana film (2).mp4'\t      'Hoveret (2).gdoc'\n",
            "'ana film (3).mp4'\t       Hoveret.gdoc\n",
            "'ana film.mp4'\t\t       IMG_0308.MOV\n",
            "'Apr 20, 2020 11:17:22.jpeg'   Screenshot_20190310-101212_WhatsApp.jpg\n",
            "'Apr 20, 2020 11:19:59.jpeg'  'Untitled form (1).gform'\n",
            "'Apr 20, 2020 11:20:22.jpeg'  'Untitled form (2).gform'\n",
            "'Apr 24, 2020 11:20:00.jpeg'  'Untitled form (3).gform'\n",
            "'Apr 24, 2020 11:20:26.jpeg'  'Untitled form.gform'\n",
            "'Apr 24, 2020 11:20:45.jpeg'   work1.html\n",
            "'Apr 24, 2020 11:21:04.jpeg'  'â€â¨××¤×•×§×¡×™×“×™× ×©×™×¢×•×¨ 2024-2025â©.pdf'\n",
            "'Apr 24, 2020 11:21:21.jpeg'  \"×‘×ª ××¦×•×”- ×¢×™×œ×™×ª ×©×•×‘×• ××©×“×•×“ ×¢''×“.mp4\"\n",
            " chaya.gaya.mp4\t\t      '×”×¦×¢×•×ª_×œ× ×•×©××™×_×œ×¢×‘×•×“×ª_×—×§×¨_×¢×œ_×¡×¤×¨_×‘×¨××©×™×ª (4)1 (2).doc'\n",
            " Classroom\t\t      '×›×ª×™×‘×” ××§×“××™×ª.docx'\n",
            "'Colab Notebooks'\t      '××—×•×•×Ÿ ×œ×¢×‘×•×“×•×ª ×ª××•× ×•×ª ××¡×¤×¨×•×ª (1).docx'\n",
            "'Document (1).docx'\t      '××˜×œ×” 2 ××ª×•×§×Ÿ (1).docx'\n",
            " Document.docx\t\t      '××˜×œ×” 2 ××ª×•×§×Ÿ.docx'\n",
            "'English project.docx'\t      '××˜×œ×”_×œ×”×’×©×”_×‘×”×™×¡×˜×•×¨×™×”[1].gdoc'\n",
            "'English project.gdoc'\t      '×¡×™×›×•××™× ××ª××˜×™×§×” ğŸŒ¸'\n",
            "'Getting started.pdf'\t      '×©× ×” ×'\n",
            "'homework1 (1).docx'\t      '×©× ×” × - ×—×™×” ×‘×¨×™×™×Ÿ '\n",
            " homework1.docx\t\t      '×ª××•× ×•×ª ×¢× ×œ×™×¨×Ÿ '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/BINA PROJECT/indian Worker/indianWorker\"\n"
      ],
      "metadata": {
        "id": "QQrHmui1hA8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8a32e4-83a0-49c4-db43-4d76bfe0248f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/BINA PROJECT/indian Worker/indianWorker': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "kmcgkW63hD6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "ZbphKpLqN-fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×”×’×“×¨×•×ª ×‘×¡×™×¡×™×•×ª ---\n",
        "batch_size = 32\n",
        "img_size = (224, 224)  # ×’×•×“×œ ×”×ª××•× ×” ×”××ª××™× ×œ××•×“×œ ResNet50\n",
        "\n",
        "# --- ×—×œ×•×§×ª ×”×ª××•× ×•×ª ×œ-Train, Validation ×•-Test ---\n",
        "source_dir_light = \"/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/light\"  # × ×ª×™×‘ ×œ×ª××•× ×•×ª ×§×œ×•×ª\n",
        "source_dir_severe = \"/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/severe\"  # × ×ª×™×‘ ×œ×ª××•× ×•×ª ×—××•×¨×•×ª\n",
        "output_dir = \"/content/drive/MyDrive/BINA PROJECT/indian Worker/indianWorker/split_data_resnet50\"  # × ×ª×™×‘ ×œ×©××™×¨×ª ×”×ª××•× ×•×ª ×”××—×•×œ×§×•×ª\n",
        "\n",
        "# ××—×•×–×™ ×—×œ×•×§×”\n",
        "test_split = 0.1 #  10% ×œ×§×‘×•×¦×ª ×”×‘×“×™×§×”\n",
        "val_split = 0.3  # 30% ×œ×§×‘×•×¦×ª ×”×•×œ×™×“×¦×™×”"
      ],
      "metadata": {
        "id": "w_G8S-aOOFue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ×¤×•× ×§×¦×™×” ×œ×—×œ×•×§×ª ×ª××•× ×•×ª\n",
        "def split_data(source_dir, output_dir, category, test_split, val_split):\n",
        "    files = os.listdir(source_dir)\n",
        "    random.shuffle(files)\n",
        "\n",
        "    test_size = int(len(files) * test_split)\n",
        "    val_size = int(len(files) * val_split)\n",
        "\n",
        "    test_files = files[:test_size]\n",
        "    val_files = files[test_size:test_size + val_size]\n",
        "    train_files = files[test_size + val_size:]\n",
        "\n",
        "    # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª\n",
        "    for split, split_files in zip(['train', 'val', 'test'], [train_files, val_files, test_files]):\n",
        "        split_dir = os.path.join(output_dir, split, category)\n",
        "        os.makedirs(split_dir, exist_ok=True)\n",
        "        for file in split_files:\n",
        "            shutil.copy(os.path.join(source_dir, file), os.path.join(split_dir, file))"
      ],
      "metadata": {
        "id": "XNAw9jh4PxGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/BINA PROJECT/indian Worker/indianWorker\"\n",
        "!find /content/drive -name \"light\"\n",
        "!find /content/drive -name \"severe\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l5g7WfHWaIXs",
        "outputId": "b9800c46-192e-4d03-c1b0-d7d2c930c510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/BINA PROJECT/indian Worker/indianWorker': No such file or directory\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/train/light\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/val/light\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/test/light\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/light\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/train/light\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/val/light\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/test/light\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/light\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/train/severe\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/val/severe\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/test/severe\n",
            "/content/drive/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/severe\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/train/severe\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/val/severe\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/split_data_cnn/test/severe\n",
            "/content/drive/.Encrypted/MyDrive/Colab Notebooks/BINA PROJECT/indian Worker/indianWorker/severe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import shutil\n",
        "\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/BINA PROJECT/indian Worker/indianWorker/split_data_resnet50\"\n",
        "\n",
        "# ×—×œ×•×§×ª ×”×ª××•× ×•×ª\n",
        "split_data(source_dir_light, output_dir, \"light\", test_split, val_split)\n",
        "split_data(source_dir_severe, output_dir, \"severe\", test_split, val_split)"
      ],
      "metadata": {
        "id": "RuZFM6U6P2_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×˜×¢×™× ×ª ×”×“××˜×” ---\n",
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(output_dir, \"train\"),\n",
        "    labels='inferred',\n",
        "    label_mode='binary',  # ×¡×™×•×•×’ ×‘×™× ××¨×™\n",
        "    batch_size=batch_size,\n",
        "    image_size=img_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "train_data = train_data.unbatch()\n",
        "\n",
        "# Oversampling ×œ×§×˜×’×•×¨×™×” 'Severe'\n",
        "def oversample_category(dataset, category_label):\n",
        "    images, labels = [], []\n",
        "    for x, y in dataset:\n",
        "        images.append(x)\n",
        "        labels.append(y)\n",
        "        if tf.reduce_all(y == category_label):  # ×©×›×¤×•×œ ×”×§×˜×’×•×¨×™×” ×”×—×œ×©×”\n",
        "            images.append(x)\n",
        "            labels.append(y)\n",
        "\n",
        "    # ×‘×“×™×§×” ×©×›×œ ×”×˜× ×¡×•×¨×™× ×”× ×‘××•×ª×• ×’×•×“×œ\n",
        "    assert all(img.shape == images[0].shape for img in images), \"Shapes do not match!\"\n",
        "\n",
        "    # ×”×—×–×¨×ª ×“××˜×”×¡×˜\n",
        "    return tf.data.Dataset.from_tensor_slices((tf.stack(images), tf.stack(labels)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fMLsA0UP4ts",
        "outputId": "6a36af17-b4b0-4007-e5e1-22ce73ae1395",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 644 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×˜×¢×™× ×ª ×”×“××˜×” ---\n",
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(output_dir, \"train\"),\n",
        "    labels='inferred',\n",
        "    label_mode='binary',  # ×¡×™×•×•×’ ×‘×™× ××¨×™\n",
        "    batch_size=batch_size,\n",
        "    image_size=img_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(output_dir, \"val\"),\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    batch_size=batch_size,\n",
        "    image_size=img_size\n",
        ")\n",
        "\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(output_dir, \"test\"),\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    batch_size=batch_size,\n",
        "    image_size=img_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "3VTPuIljP_L8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "0aa1bc37-fc3a-4f37-9e53-4322f3e826fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 644 files belonging to 2 classes.\n",
            "Found 299 files belonging to 2 classes.\n",
            "Found 99 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ×¤×¨×™×¡×ª ×§×‘×•×¦×•×ª (Unbatch) ×›×š ×©×›×œ ×ª××•× ×” ×ª×¢××•×“ ×‘×¤× ×™ ×¢×¦××”\n",
        "train_data = train_data.unbatch()\n",
        "\n",
        "# ×©×™× ×•×™ ×’×•×“×œ ×©×œ ×”×ª××•× ×•×ª ×œ-224x224 ×›×“×™ ×œ×”×‘×˜×™×— ××—×™×“×•×ª\n",
        "resize_layer = tf.keras.layers.Resizing(224, 224)\n",
        "train_data = train_data.map(lambda x, y: (resize_layer(x), y))\n"
      ],
      "metadata": {
        "id": "WY8G0Rkvkq-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# × ×™×¨××•×œ ×”×¤×™×§×¡×œ×™× ×œ×˜×•×•×— 0-1\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "\n",
        "# Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomBrightness(0.2),  # ×©×™× ×•×™ ×‘×‘×”×™×¨×•×ª\n",
        "    layers.RandomContrast(0.2)    # ×©×™× ×•×™ ×‘× ×™×’×•×“×™×•×ª\n",
        "])\n",
        "\n",
        "\n",
        "train_data = train_data.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_data = val_data.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_data = test_data.map(lambda x, y: (normalization_layer(x), y))\n"
      ],
      "metadata": {
        "id": "txBmp37EQA_T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3d612741-4a75-43b8-8e79-a2841b1ff886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'layers' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-cbb8d2f24df9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# × ×™×¨××•×œ ×”×¤×™×§×¡×œ×™× ×œ×˜×•×•×— 0-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnormalization_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRescaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Data Augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m data_augmentation = tf.keras.Sequential([\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×‘× ×™×™×ª ×”××•×“×œ ---\n",
        "# ×˜×¢×™× ×ª ×”××•×“×œ ×”×××•××Ÿ ××¨××© (EfficientNetB0)\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "\n",
        "# ×”×§×¤××ª ×”×©×›×‘×•×ª ×©×œ ×”××•×“×œ ×”×××•××Ÿ\n",
        "base_model.trainable = False\n",
        "\n",
        "# ×”×•×¡×¤×ª ×©×›×‘×•×ª ××•×ª×××•×ª ××™×©×™×ª\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # ×¡×™×•×•×’ ×‘×™× ××¨×™: ×§×œ/×—××•×¨\n",
        "])\n",
        "\n",
        "# ×§×•××¤×™×œ×¦×™×” ×©×œ ×”××•×“×œ\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),  # ×§×¦×‘ ×œ××™×“×” ××”×™×¨ ×™×•×ª×¨\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "I41pRChVQGMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×”×’×“×¨×ª ××¡×¤×¨ ×”××¤×•×§×™× ---\n",
        "epochs = 10  # ××¡×¤×¨ ×”××¤×•×§×™× ×œ××™××•×Ÿ ×”×¨××©×•× ×™\n",
        "\n",
        "# --- Early Stopping ---\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # ××¤×©×¨ ×’× 'val_accuracy' ×œ×¤×™ ××˜×¨×ª×š\n",
        "    patience=5,  # ××¡×¤×¨ ×”××¤×•×§×™× ×œ×œ× ×©×™×¤×•×¨ ×œ×¤× ×™ ×¢×¦×™×¨×”\n",
        "    restore_best_weights=True  # ×©×—×–×•×¨ ×”××©×§×œ×™× ×”×˜×•×‘×™× ×‘×™×•×ª×¨\n",
        ")\n",
        "\n",
        "# --- ××©×§×œ×™× ×œ×§×˜×’×•×¨×™×•×ª ---\n",
        "class_weights = {0: 1.0, 1: 2.0}  # ×œ×“×•×’××”, ×¢×“×™×¤×•×ª ×œ×§×˜×’×•×¨×™×” 'Severe'\n",
        "\n",
        "# --- ××™××•×Ÿ ×”××•×“×œ ×”×¨××©×•× ×™ ---\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,  # ×”×•×¡×¤×ª ××©×§×œ×™× ×œ×§×˜×’×•×¨×™×•×ª\n",
        "    callbacks=[early_stopping]  # ×”×•×¡×¤×ª Early Stopping\n",
        ")\n"
      ],
      "metadata": {
        "id": "UuKyMcm9QKjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×©×—×¨×•×¨ ×©×›×‘×•×ª × ×•×¡×¤×•×ª ×‘-ResNet50 ---\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# ×§×•××¤×™×œ×¦×™×” ××—×“×© ×¢× ×§×¦×‘ ×œ××™×“×” ××”×™×¨ ×™×•×ª×¨\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # ×§×¦×‘ ×œ××™×“×” ××”×™×¨\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "9eqQNRtr1jhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fine-Tuning ---\n",
        "fine_tune_epochs = 10\n",
        "history_fine = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=fine_tune_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Kz4lG1Uu1sVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×•×™×–×•××œ×™×–×¦×™×” ×œ××—×¨ Fine-Tuning ---\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history_fine.history['accuracy'], label='Training Accuracy (Fine-Tune)')\n",
        "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy (Fine-Tune)')\n",
        "plt.title('Accuracy over Epochs (Fine-Tuning)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sgrdM2v41zjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history_fine.history['loss'], label='Training Loss (Fine-Tune)')\n",
        "plt.plot(history_fine.history['val_loss'], label='Validation Loss (Fine-Tune)')\n",
        "plt.title('Loss over Epochs (Fine-Tuning)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6xKMD_HW10qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ×”×¢×¨×›×ª ×”××•×“×œ ×¢×œ ×§×‘×•×¦×ª ×”×‘×“×™×§×” ---\n",
        "print(\"\\nEvaluating on Test Data...\")\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "82YRS2esQcWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ×—×™×–×•×™ ×¢×œ ×§×‘×•×¦×ª ×”×‘×“×™×§×”\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for images, labels in test_data:\n",
        "    predictions = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
        "\n",
        "# --- ×—×™×©×•×‘ ××“×“×™× × ×•×¡×¤×™× ---\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Light\", \"Severe\"]))"
      ],
      "metadata": {
        "id": "T2dTzvb9QhZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ××˜×¨×™×¦×ª ×‘×œ×‘×•×œ\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# ×•×™×–×•××œ×™×–×¦×™×” ×©×œ ××˜×¨×™×¦×ª ×”×‘×œ×‘×•×œ\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(conf_matrix, cmap=\"Blues\", interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.xticks([0, 1], [\"Light\", \"Severe\"])\n",
        "plt.yticks([0, 1], [\"Light\", \"Severe\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cuesDL87QlGu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}